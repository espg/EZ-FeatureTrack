{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://github.com/nasa-jpl/itslive\n",
    "\n",
    "<!-- <div align=\"center\"> \n",
    "<img src='./img/header.png'/>\n",
    "</div> -->\n",
    "\n",
    "## [Global Ice Velocities](https://its-live.jpl.nasa.gov/)\n",
    "    \n",
    "The Inter-mission Time Series of Land Ice Velocity and Elevation (ITS_LIVE) project facilitates ice sheet, ice shelf and glacier research by providing a globally comprehensive and temporally dense multi-sensor record of land ice velocity and elevation with low latency.\n",
    "\n",
    "Scene-pair velocities generated from satellite optical and radar imagery.\n",
    "\n",
    "* Coverage: All land ice\n",
    "* Date range: 1985-present\n",
    "* Resolution: 240m\n",
    "* Scene-pair separation: 6 to 546 days\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "* If you want to query our API directly using  your own software here is the OpenApi endpoint https://staging.nsidc.org/apps/itslive-search/docs\n",
    "* For questions about this notebook and the dataset please contact users services at uso@nsidc.org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efc0342887143079d1c410625ffef7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Hemisphere:', index=2, options=('global', 'south', 'north'), value='north')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576714c0b76b4432a5ab82d06e5d490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Minimum % of valid pixels per image pair:'), Dropdown(layout=Layout(display='flex'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0e01e810634679b578eae9db1a6c88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Label(value='Maximum days of separation between image pairs:'), Dropdown(layout=Layout(display=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c94f48a73024d1881778b72b343cbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectionRangeSlider(description='Date Range', index=(0, 13149), layout=Layout(width='100%'), options=((' 1984…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc3d884e9534d0b904bd00ca3f25abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[90, 0], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoom_out_text…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1: Now let's render our UI and pick up an hemisphere, if you update the hemisphere you need to execute the cell again.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itslive import itslive_ui\n",
    "ui = itslive_ui('north')\n",
    "ui.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current parameters: {'polygon': '-49.3013,69.5357,-49.3013,69.5377,-49.2993,69.5377,-49.2993,69.5357,-49.3013,69.5357', 'start': '2014-07-22', 'end': '2020-01-01', 'percent_valid_pixels': 1}\n",
      "Total data granules: 7,155\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'count': 550, 'year': 2014},\n",
       " {'count': 1261, 'year': 2015},\n",
       " {'count': 1417, 'year': 2016},\n",
       " {'count': 2031, 'year': 2017},\n",
       " {'count': 1896, 'year': 2018}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2: We build the parameters to query the ITS_LIVE Search API, we get the time coverage for our selected area\n",
    "params = ui.build_params()\n",
    "print(f'current parameters: {params}')\n",
    "timeline = None\n",
    "if params is not None:\n",
    "    timeline = ui.update_coverages()\n",
    "    total =  sum(item['count'] for item in timeline)\n",
    "    print(f'Total data granules: {total:,}')\n",
    "timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32623/LC08_L1GT_009011_20160910_20180130_01_T2_X_LC08_L1TP_009011_20160606_20170324_01_T1_G0240V01_P010.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32623/LC08_L1GT_008011_20150901_20170404_01_T2_X_LC08_L1TP_008011_20140626_20170421_01_T1_G0240V01_P002.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32623/LC08_L1TP_008011_20150426_20170409_01_T1_X_LC08_L1TP_008011_20140626_20170421_01_T1_G0240V01_P003.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32623/LC08_L1TP_008011_20150528_20180130_01_T1_X_LC08_L1TP_008011_20140626_20170421_01_T1_G0240V01_P002.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_008011_20150731_20170406_01_T1_X_LC08_L1TP_008011_20140306_20170425_01_T1_G0240V01_P006.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_008011_20160717_20180130_01_T1_X_LC08_L1TP_008011_20150528_20170408_01_T1_G0240V01_P015.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_008011_20170517_20170525_01_T1_X_LC08_L1TP_008011_20160802_20170322_01_T1_G0240V01_P009.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_008011_20170602_20170615_01_T1_X_LC08_L1TP_008011_20160717_20170323_01_T1_G0240V01_P011.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_008011_20170821_20170911_01_T1_X_LC08_L1TP_008011_20160530_20170324_01_T1_G0240V01_P014.nc'}\n",
      "{'url': 'http://its-live-data.jpl.nasa.gov.s3.amazonaws.com/velocity_image_pair/landsat/v00.0/32622/LC08_L1TP_010011_20150713_20170407_01_T1_X_LC08_L1TP_010011_20150307_20170412_01_T1_G0240V01_P031.nc'}\n"
     ]
    }
   ],
   "source": [
    "#3: Now we are going to get the velocity pair urls, this does not download the files yet just their location\n",
    "urls = []\n",
    "params = ui.build_params()\n",
    "if params is not None:\n",
    "    urls = ui.get_granule_urls(params)\n",
    "    # Print the first 10 granule URLs\n",
    "    for url in urls[0:10]:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering granules by year and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4: This will query AWS(where the granules are stored) so we know the total size of our first N granules\n",
    "# This may take some time, try reducing the selected area or constraining the other parameters to download a reasonable number of granules.\n",
    "url_list = [url['url'] for url in urls]\n",
    "# urls\n",
    "filtered_urls = ui.filter_urls(url_list, max_files_per_year=5, months=[3,4,5,6,7])\n",
    "\n",
    "# max_granules = 100\n",
    "# sizes = ui.calculate_file_sizes(filtered_urls, max_granules)\n",
    "# total_zise = round(sum(sizes)/1024,2)\n",
    "# print(f'Approx size to download for the first {max_granules:,} granules: {total_zise} MB')\n",
    "print(len(filtered_urls))\n",
    "filtered_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the data\n",
    "**Now that we have our list of data granules we can download them from AWS.**\n",
    "\n",
    "If this notebook is running inside AWS we could load the granules into a Dask cluster and reduce our processing times and costs.\n",
    "Let's get some coffee, some data requests are in the Gigabytes realm and may take a little while to be processed. \n",
    "Once that your status URL says is completed we can grab the HDF5 data file using the URL on the same response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 This will download the first 50 velocity pairs\n",
    "files = ui.download_velocity_pairs(filtered_urls, start=0, end=50)\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from shapely.geometry import Polygon\n",
    "warnings.filterwarnings('ignore')\n",
    "centroid = ui.dc.last_draw['geometry']['coordinates']\n",
    "# coord = [-49.59321, 69.210579]\n",
    "#loads an array of xarray datasets from the nc files\n",
    "velocity_pairs = ui.load_velocity_pairs('data')\n",
    "\n",
    "centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = []\n",
    "mean_offset_meters = 1200\n",
    "for ds in velocity_pairs:\n",
    "    proj = str(int(ds.UTM_Projection.spatial_epsg))\n",
    "    selected_coord = ui.transform_coord('4326',proj, centroid[0], centroid[1])\n",
    "    projected_lon = round(selected_coord[0])\n",
    "    projected_lat = round(selected_coord[1])\n",
    "    mid_date = datetime.strptime(ds.img_pair_info.date_center,'%Y%m%d')\n",
    "    # We are going to calculate the mean value of the neighboring pixels(each is 240m) 10 x 10 window\n",
    "    mask_lon = (ds.x >= projected_lon - mean_offset_meters) & (ds.x <= projected_lon + mean_offset_meters)\n",
    "    mask_lat = (ds.y >= projected_lat - mean_offset_meters) & (ds.y <= projected_lat + mean_offset_meters)\n",
    "    v = ds.where(mask_lon & mask_lat , drop=True).v.mean(skipna=True)\n",
    "    # If we have a valid value we add it to the velocities array.\n",
    "    if not np.isnan(v):\n",
    "        velocities.append({'date': mid_date, 'mean_velocity': v.values.ravel()[0]})\n",
    "velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# order by date\n",
    "df = pd.DataFrame(velocities)\n",
    "df = df.sort_values(by='date').reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x ='date', y='mean_velocity', kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocity_pairs[0].plot.scatter(x='x', y='y', hue='v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
